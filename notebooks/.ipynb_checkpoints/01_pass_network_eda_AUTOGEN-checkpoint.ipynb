{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad012803",
   "metadata": {},
   "source": [
    "# Pass Network EDA ‚Äî AUTOGEN üìä‚öΩ\n",
    "\n",
    "Notebook autosuficiente para explorar **redes de pases** a partir de un CSV tipo WhoScored y los artefactos generados por `scripts/build_graph.py`.\n",
    "\n",
    "**Requisitos previos (en tu entorno `futgnn`):**\n",
    "- `pandas`, `networkx`, `matplotlib`, `torch`, `torch_geometric`\n",
    "- Haber generado `data/processed/passes_GLOBAL.gpickle` y `passes_GLOBAL.pt` con el script de construcci√≥n (o usa el *batch* incluido).\n",
    "\n",
    "> Puedes editar los par√°metros (archivo CSV, umbrales de inferencia) en la siguiente celda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b1b679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Utils + Par√°metros ===\n",
    "from pathlib import Path\n",
    "import pandas as pd, pickle, networkx as nx\n",
    "import torch\n",
    "\n",
    "# Localiza la ra√≠z del repo (carpetas 'data' y 'src')\n",
    "def find_repo_root(start: Path | None = None) -> Path:\n",
    "    p = (start or Path.cwd()).resolve()\n",
    "    for cand in [p, *p.parents]:\n",
    "        if (cand / \"data\").exists() and (cand / \"src\").exists():\n",
    "            return cand\n",
    "    return p\n",
    "\n",
    "def read_gpickle_robust(path: Path):\n",
    "    # Carga un .gpickle con fallback a pickle puro (por compatibilidad).\n",
    "    try:\n",
    "        from networkx.readwrite.gpickle import read_gpickle\n",
    "        return read_gpickle(path)\n",
    "    except Exception:\n",
    "        with open(path, \"rb\") as f:\n",
    "            return pickle.load(f)\n",
    "\n",
    "def map_from(df, key, value):\n",
    "    # Crea dict df[key] -> df[value], si ambas columnas existen.\n",
    "    if key in df and value in df:\n",
    "        return (df[[key, value]].dropna().drop_duplicates(key).set_index(key)[value].to_dict())\n",
    "    return {}\n",
    "\n",
    "# --- Par√°metros editables ---\n",
    "CSV_NAME   = \"Atletico Madrid 1-0 Real Madrid-Champions League-2025-04-07.csv\"  # cambia aqu√≠ si quieres otro CSV\n",
    "NEAR_DIST  = 10.0\n",
    "LOOKAHEAD  = 15\n",
    "\n",
    "ROOT   = find_repo_root()\n",
    "RAW    = ROOT / \"data\" / \"raw\" / CSV_NAME\n",
    "PROC_G = ROOT / \"data\" / \"processed\" / \"passes_GLOBAL.gpickle\"\n",
    "PROC_PT= ROOT / \"data\" / \"processed\" / \"passes_GLOBAL.pt\"\n",
    "\n",
    "print(\"ROOT:\", ROOT)\n",
    "print(\"RAW exists?    \", RAW.exists(), RAW)\n",
    "print(\"PROC_G exists? \", PROC_G.exists(), PROC_G)\n",
    "print(\"PROC_PT exists?\", PROC_PT.exists(), PROC_PT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53058461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Carga de eventos y artefactos ===\n",
    "# Si no existen los artefactos GLOBAL, puedes generarlos con el batch (archivo: batch_build_and_report.py)\n",
    "events = pd.read_csv(RAW, encoding=\"utf-8-sig\", on_bad_lines=\"skip\")\n",
    "\n",
    "# Grafo NetworkX\n",
    "G = read_gpickle_robust(PROC_G)\n",
    "\n",
    "# Objeto PyG (opcional, para features nodales)\n",
    "data = torch.load(PROC_PT)\n",
    "print((G.number_of_nodes(), G.number_of_edges()), data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1cd206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Mapeos m√≠nimos y posici√≥n promedio (x,y) por jugador ===\n",
    "name_map  = map_from(events, \"playerId\", \"shortName\")\n",
    "shirt_map = map_from(events, \"playerId\", \"shirtNo\")\n",
    "team_map  = map_from(events, \"playerId\", \"teamId\")\n",
    "\n",
    "if all(c in events.columns for c in [\"playerId\",\"x\",\"y\",\"type\"]):\n",
    "    pos_df = events[events[\"type\"].astype(str).str.lower().eq(\"pass\")][[\"playerId\",\"x\",\"y\"]].dropna()\n",
    "    pos_xy = pos_df.groupby(\"playerId\")[[\"x\",\"y\"]].mean().to_dict(\"index\")\n",
    "else:\n",
    "    pos_xy = {}\n",
    "\n",
    "print(\"Players with names:\", len(name_map))\n",
    "print(\"Players with avg pos:\", len(pos_xy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e47ffdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Res√∫menes r√°pidos ===\n",
    "import numpy as np\n",
    "\n",
    "edges = [{\n",
    "    \"from_id\": u,\n",
    "    \"to_id\": v,\n",
    "    \"weight\": d.get(\"weight\", 1),\n",
    "    \"success_rate\": (d.get(\"success_count\", 0) / max(1, d.get(\"weight\", 1))),\n",
    "    \"dist_avg\": (d.get(\"dist_sum\", 0.0) / max(1, d.get(\"weight\", 1))),\n",
    "} for u, v, d in G.edges(data=True)]\n",
    "edges_df = pd.DataFrame(edges).sort_values(\"weight\", ascending=False)\n",
    "\n",
    "nodes = [{\n",
    "    \"player_id\": n,\n",
    "    \"name\": name_map.get(n, str(n)),\n",
    "    \"shirt\": shirt_map.get(n),\n",
    "    \"team\": team_map.get(n),\n",
    "    \"deg_out\": G.out_degree(n),\n",
    "    \"deg_in\": G.in_degree(n),\n",
    "    \"x_mean\": pos_xy.get(n, {}).get(\"x\", np.nan),\n",
    "    \"y_mean\": pos_xy.get(n, {}).get(\"y\", np.nan),\n",
    "} for n in G.nodes()]\n",
    "nodes_df = pd.DataFrame(nodes).sort_values([\"team\",\"deg_out\"], ascending=[True, False])\n",
    "\n",
    "edges_df.head(10), nodes_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcb0677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Punto 3: Centralidades (grado/strength, betweenness, PageRank) ===\n",
    "import numpy as np, networkx as nx\n",
    "from IPython.display import display\n",
    "\n",
    "deg_out = dict(G.out_degree())\n",
    "deg_in  = dict(G.in_degree())\n",
    "\n",
    "out_strength = {n: 0.0 for n in G.nodes()}\n",
    "in_strength  = {n: 0.0 for n in G.nodes()}\n",
    "for u, v, d in G.edges(data=True):\n",
    "    w = float(d.get('weight', 1))\n",
    "    out_strength[u] += w\n",
    "    in_strength[v]  += w\n",
    "\n",
    "bet_unw = nx.betweenness_centrality(G, normalized=True)\n",
    "\n",
    "H = G.copy()\n",
    "for u, v, d in H.edges(data=True):\n",
    "    w = float(d.get('weight', 1))\n",
    "    d['length'] = 1.0 / max(w, 1e-9)\n",
    "bet_w = nx.betweenness_centrality(H, normalized=True, weight='length')\n",
    "\n",
    "try:\n",
    "    pr_w = nx.pagerank(G, alpha=0.85, weight='weight', max_iter=100)\n",
    "except Exception:\n",
    "    pr_w = {n: np.nan for n in G.nodes()}\n",
    "\n",
    "nodes_df = nodes_df.set_index('player_id')\n",
    "nodes_df['str_out']       = nodes_df.index.map(out_strength.get)\n",
    "nodes_df['str_in']        = nodes_df.index.map(in_strength.get)\n",
    "nodes_df['betweenness']   = nodes_df.index.map(bet_unw.get)\n",
    "nodes_df['betweenness_w'] = nodes_df.index.map(bet_w.get)\n",
    "nodes_df['pagerank_w']    = nodes_df.index.map(pr_w.get)\n",
    "nodes_df = nodes_df.reset_index()\n",
    "\n",
    "def top(df, col, k=15):\n",
    "    cols = [c for c in ['name','player_id','team','shirt',col] if c in df.columns]\n",
    "    return df.sort_values(col, ascending=False)[cols].head(k)\n",
    "\n",
    "print(\"Top betweenness (no ponderado):\")\n",
    "display(top(nodes_df, 'betweenness'))\n",
    "print(\"Top betweenness (ponderado 1/weight):\")\n",
    "display(top(nodes_df, 'betweenness_w'))\n",
    "print(\"Top PageRank (ponderado):\")\n",
    "display(top(nodes_df, 'pagerank_w'))\n",
    "print(\"Top out-strength (suma de pesos):\")\n",
    "display(top(nodes_df, 'str_out'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcdd0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Visualizaci√≥n: red de pases con layout por posici√≥n promedio ===\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "pos, missing = {}, []\n",
    "for n in G.nodes():\n",
    "    xy = pos_xy.get(n)\n",
    "    if xy is not None:\n",
    "        pos[n] = (float(xy[\"x\"]), float(xy[\"y\"]))\n",
    "    else:\n",
    "        missing.append(n)\n",
    "if missing:\n",
    "    spring_pos = nx.spring_layout(G.subgraph(missing), seed=1)\n",
    "    for n in missing:\n",
    "        pos[n] = spring_pos[n]\n",
    "\n",
    "plt.figure(figsize=(8, 10))\n",
    "weights = [min(4, 0.2 * d.get(\"weight\", 1)) for *_, d in G.edges(data=True)]\n",
    "nx.draw_networkx_edges(G, pos, width=weights, arrows=True, arrowsize=10)\n",
    "nx.draw_networkx_nodes(G, pos, node_size=120)\n",
    "labels = {n: name_map.get(n, str(n)) for n in G.nodes()}\n",
    "nx.draw_networkx_labels(G, pos, labels=labels, font_size=7)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Red de pases (layout por posici√≥n promedio)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea95654d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Matriz de pases (origen √ó destino) ===\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "out_strength_order = edges_df.groupby(\"from_id\")[\"weight\"].sum().sort_values(ascending=False).index.tolist()\n",
    "in_strength_order  = edges_df.groupby(\"to_id\")[\"weight\"].sum().sort_values(ascending=False).index.tolist()\n",
    "\n",
    "mat = edges_df.pivot_table(index=\"from_id\", columns=\"to_id\", values=\"weight\", fill_value=0)\n",
    "mat = mat.reindex(index=out_strength_order, columns=in_strength_order)\n",
    "\n",
    "row_labels = [name_map.get(i, str(i)) for i in mat.index]\n",
    "col_labels = [name_map.get(i, str(i)) for i in mat.columns]\n",
    "\n",
    "plt.figure(figsize=(9, 8))\n",
    "plt.imshow(mat.values, aspect=\"auto\")\n",
    "plt.colorbar(label=\"# pases\")\n",
    "plt.xticks(range(len(col_labels)), col_labels, rotation=90, fontsize=6)\n",
    "plt.yticks(range(len(row_labels)), row_labels, fontsize=6)\n",
    "plt.title(\"Matriz de pases (origen √ó destino)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444aad4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Export: tablas y figuras a /data/processed ===\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "OUT_DIR = ROOT / \"data\" / \"processed\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Guarda CSVs\n",
    "nodes_csv = OUT_DIR / \"nodes_GLOBAL.csv\"\n",
    "edges_csv = OUT_DIR / \"edges_GLOBAL.csv\"\n",
    "nodes_df.to_csv(nodes_csv, index=False)\n",
    "edges_df.to_csv(edges_csv, index=False)\n",
    "print(\"CSV guardados:\", nodes_csv, edges_csv)\n",
    "\n",
    "# Guarda figuras\n",
    "FIG_DIR = ROOT / \"reports\" / \"figures\"\n",
    "FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Red\n",
    "plt.figure(figsize=(8, 10))\n",
    "weights = [min(4, 0.2 * d.get(\"weight\", 1)) for *_, d in G.edges(data=True)]\n",
    "nx.draw_networkx_edges(G, pos, width=weights, arrows=True, arrowsize=10)\n",
    "nx.draw_networkx_nodes(G, pos, node_size=120)\n",
    "labels = {n: name_map.get(n, str(n)) for n in G.nodes()}\n",
    "nx.draw_networkx_labels(G, pos, labels=labels, font_size=7)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Red de pases (layout por posici√≥n promedio)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIG_DIR / \"pass_network_GLOBAL.png\", dpi=200)\n",
    "plt.close()\n",
    "\n",
    "# Matriz\n",
    "import numpy as np\n",
    "plt.figure(figsize=(9, 8))\n",
    "plt.imshow(mat.values, aspect=\"auto\")\n",
    "plt.colorbar(label=\"# pases\")\n",
    "plt.xticks(range(len(col_labels)), col_labels, rotation=90, fontsize=6)\n",
    "plt.yticks(range(len(row_labels)), row_labels, fontsize=6)\n",
    "plt.title(\"Matriz de pases (origen √ó destino)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIG_DIR / \"pass_matrix_GLOBAL.png\", dpi=200)\n",
    "plt.close()\n",
    "\n",
    "print(\"Figuras guardadas en:\", FIG_DIR)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}